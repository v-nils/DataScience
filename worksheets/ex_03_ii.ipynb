{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T19:22:10.449502Z",
     "start_time": "2024-04-29T19:22:10.444189Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend\n",
    "\n",
    "import h5py\n",
    "from scipy import ndimage\n",
    "\n",
    "# block averaging for image degradation\n",
    "def block_mean(ar, fact):\n",
    "    assert isinstance(fact, int), type(fact)\n",
    "    sx, sy = ar.shape\n",
    "    X, Y = np.ogrid[0:sx, 0:sy]\n",
    "    regions = sy//fact * (X//fact) + Y//fact\n",
    "    res = ndimage.mean(ar, labels=regions, index=np.arange(regions.max() + 1))\n",
    "    res.shape = (sx//fact, sy//fact)\n",
    "    return res\n",
    "\n"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the dataset, normalise and scale"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T19:22:10.931419Z",
     "start_time": "2024-04-29T19:22:10.476660Z"
    }
   },
   "source": [
    "###########################################################\n",
    "# load galaxy images from hdf5 file\n",
    "ndown = 4\n",
    "# use first 256 galaxies as training data\n",
    "with h5py.File('data/raw_data/DECals_galaxies.hdf5', 'r') as F:\n",
    "  images = np.array( F['images_spirals'] )\n",
    "  # make grayscale\n",
    "  images = np.mean(images, axis=-1)\n",
    "  # downsample by 4\n",
    "  imagesd = np.zeros((images.shape[0],images.shape[1]//ndown, images.shape[2]//ndown))\n",
    "  for i in range( images.shape[0] ):\n",
    "    imagesd[i,...] = block_mean( images[i,...], ndown )\n",
    "  images = imagesd / 255\n",
    "\n",
    "IMAGE_SIZE = images.shape[1]\n",
    "CHANNELS   = 1\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "###########################################################\n",
    "# split into training and test data (first 32 galaxies are test data)\n",
    "x_train = images[32:,:,:,None]\n",
    "x_test  = images[:32,:,:,None]\n",
    "\n",
    "###########################################################\n",
    "# enable data augmentation, i.e. we randomly show the images flipped horizontally and vertically when training\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "])\n",
    "\n",
    "###########################################################\n",
    "#convert numpy arrays to tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train,x_train)).batch( BATCH_SIZE )\n",
    "aug_ds = train_dataset.map( lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test,x_test)).batch( BATCH_SIZE )"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the encoder"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T19:22:10.965944Z",
     "start_time": "2024-04-29T19:22:10.931931Z"
    }
   },
   "source": [
    "# define hyperparameters\n",
    "EMBEDDING_DIM = 4\n",
    "EPOCHS = 400\n",
    "\n",
    "# Encoder\n",
    "encoder_input = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS), name=\"encoder_input\")\n",
    "x = layers.Conv2D(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(encoder_input)\n",
    "x = layers.Conv2D(64, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2D(128, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "shape_before_flattening = backend.int_shape(x)[1:]  # the decoder will need this!\n",
    "x = layers.Flatten()(x)\n",
    "encoder_output = layers.Dense(EMBEDDING_DIM, name=\"encoder_output\")(x)\n",
    "encoder = models.Model(encoder_input, encoder_output)\n",
    "encoder.summary()"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the decoder"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T19:22:11.003783Z",
     "start_time": "2024-04-29T19:22:10.965944Z"
    }
   },
   "source": [
    "# Decoder\n",
    "decoder_input = layers.Input(shape=(EMBEDDING_DIM,), name=\"decoder_input\")\n",
    "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "x = layers.Reshape(shape_before_flattening)(x)\n",
    "x = layers.Conv2DTranspose( 128, (3, 3), strides=2, activation=\"relu\", padding=\"same\" )(x)\n",
    "x = layers.Conv2DTranspose(  64, (3, 3), strides=2, activation=\"relu\", padding=\"same\" )(x)\n",
    "x = layers.Conv2DTranspose(  32, (3, 3), strides=2, activation=\"relu\", padding=\"same\" )(x)\n",
    "decoder_output = layers.Conv2D(CHANNELS, (3, 3), strides=1, activation=\"sigmoid\", padding=\"same\", name=\"decoder_output\")(x)\n",
    "decoder = models.Model(decoder_input, decoder_output)\n",
    "decoder.summary()"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T19:22:11.026948Z",
     "start_time": "2024-04-29T19:22:11.006154Z"
    }
   },
   "source": [
    "# Autoencoder\n",
    "autoencoder = models.Model( encoder_input, decoder(encoder_output) ) \n",
    "autoencoder.summary()\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T19:25:38.686168Z",
     "start_time": "2024-04-29T19:22:11.027956Z"
    }
   },
   "source": [
    "# train the autoencoder\n",
    "autoencoder.fit( train_dataset, epochs=EPOCHS, shuffle=True, validation_data=test_dataset )"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T19:25:38.832301Z",
     "start_time": "2024-04-29T19:25:38.686168Z"
    }
   },
   "source": [
    "# Save the final models\n",
    "autoencoder.save(\"./data/results/ex_03/models/autoencoder.keras\")\n",
    "encoder.save(\"./data/results/ex_03/models/encoder.keras\")\n",
    "decoder.save(\"./data/results/ex_03/models/decoder.keras\")"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T19:25:39.063975Z",
     "start_time": "2024-04-29T19:25:38.833821Z"
    }
   },
   "source": [
    "n_to_predict = 5\n",
    "example_images = x_test[:n_to_predict]\n",
    "predictions = autoencoder.predict(example_images)"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T19:39:27.198070Z",
     "start_time": "2024-04-29T19:39:25.343887Z"
    }
   },
   "source": [
    "\n",
    "fig, ax = plt.subplots(2, n_to_predict, figsize=(8, 3))\n",
    "\n",
    "plt.suptitle(f'latent space embedding dimensions: {EMBEDDING_DIM}')\n",
    "\n",
    "for i in range(n_to_predict):\n",
    "  ax[0, i].imshow(example_images[i, ...], cmap='viridis', vmin=0, vmax=1)\n",
    "  ax[0, i].axis('off')\n",
    "  ax[1, i].imshow(predictions[i, ...], cmap='viridis', vmin=0, vmax=1)\n",
    "  ax[1, i].axis('off')\n",
    "  \n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "plt.savefig('./data/results/ex_03/autoencoder/autoencoder_results_dims_4.png')\n"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T19:35:16.525965Z",
     "start_time": "2024-04-29T19:35:09.544161Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use(['science', 'ieee'])\n",
    "\n",
    "# Pass the images through the encoder to get the latent space representations\n",
    "latent_space_values = encoder.predict(x_test)\n",
    "\n",
    "# Plot a histogram for each dimension of the latent space\n",
    "for i in range(EMBEDDING_DIM):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(latent_space_values[:, i], bins=30)\n",
    "    plt.xlim(-1.3, 3.1)\n",
    "    plt.title(f'Latent space dimension {i+1}')\n",
    "    plt.savefig(f'./data/results/ex_03/autoencoder/latent_space_histogram_{i+1}.png')\n",
    "\n",
    "# Function to generate an image from a latent space vector\n",
    "def generate_image(latent_vector, dim, value):\n",
    "    # Set one of the dimensions to a specific value while setting all others to zero\n",
    "    modified_vector = np.zeros_like(latent_vector)\n",
    "    modified_vector[dim] = value\n",
    "\n",
    "    # Pass the modified vector through the decoder to generate an image\n",
    "    generated_image = decoder.predict(modified_vector[np.newaxis, :])\n",
    "\n",
    "    return generated_image[0]\n",
    "\n",
    "# Generate and show images for each dimension of the latent space\n",
    "for i in range(EMBEDDING_DIM):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    generated_image = generate_image(latent_space_values[0], i, 1)\n",
    "    plt.imshow(generated_image, cmap='viridis')\n",
    "    plt.title(f'Generated image for dimension {i+1}')\n",
    "    plt.savefig(f'./data/results/ex_03/autoencoder/generated_image_{i+1}.png')"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
